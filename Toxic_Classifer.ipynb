{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40e18292-772f-4835-8357-3c11fec81ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text is_toxic\n",
      "0  Elon Musk is a piece of shit, greedy capitalis...    Toxic\n",
      "1  The senile credit card shrill from Delaware ne...    Toxic\n",
      "2  He does that a lot -- makes everyone look good...    Toxic\n",
      "3                                         F*ck Lizzo    Toxic\n",
      "4  Epstein and trump were best buds!!! Pedophiles...    Toxic\n",
      "text        0\n",
      "is_toxic    0\n",
      "dtype: int64\n",
      "is_toxic\n",
      "Toxic        501\n",
      "Not Toxic    499\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('toxicity_en.csv')\n",
    "\n",
    "# Check the first few rows\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Check the class distribution\n",
    "print(data['is_toxic'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da4839a4-b5c7-4c17-bbf8-03e23be038b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map labels to binary values\n",
    "data['label'] = data['is_toxic'].map({'Toxic': 1, 'Not Toxic': 0})\n",
    "\n",
    "# Basic text preprocessing\n",
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())  # Remove non-alphabetic characters and lowercase\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to the text column\n",
    "data['text'] = data['text'].apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fed52d6-7dfa-4365-9a34-200e6544dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data['text'], data['label'], test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80472af8-0b7f-4ed3-b275-adaf538138ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "\n",
    "# Fit and transform the training data, and transform the test data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e9225da-8815-4b70-ba3f-ba7d082466ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorizer saved.\n",
      "TF-IDF Vectorizer loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Save the vectorizer to a file\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "print(\"TF-IDF Vectorizer saved.\")\n",
    "\n",
    "# Step 3: Load the vectorizer for future use\n",
    "vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "print(\"TF-IDF Vectorizer loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61c44a9b-ce48-428f-996d-6363cf820a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82       104\n",
      "           1       0.79      0.86      0.83        96\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.83      0.83      0.82       200\n",
      "weighted avg       0.83      0.82      0.82       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = log_reg.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "967b96eb-326e-4cd5-ad67-0341c6af7047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75       104\n",
      "           1       0.74      0.68      0.71        96\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.73      0.73      0.73       200\n",
      "weighted avg       0.73      0.73      0.73       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae7bfba9-ba55-49b5-b042-fc19be611cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Initialize the tokenizer and fit on the training data\n",
    "vocab_size = 5000  # Limit vocabulary size to 5000 unique words\n",
    "max_len = 100  # Maximum length of each sequence\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text to sequences and pad them to ensure uniform length\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e170fc72-ab6e-42f0-8af2-f540c631e58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save Logistic Regression model (or any other trained model)\n",
    "joblib.dump(log_reg, 'logistic_regression_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aabf4e64-0c9c-41ec-8b05-915bc861d561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_model.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the Random Forest model to a file\n",
    "joblib.dump(rf_model, 'random_forest_model.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04638acb-234c-4b7e-ae79-d520c7dc2457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Assuming `tokenizer` is already fitted on your training data\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    joblib.dump(tokenizer, f)\n",
    "\n",
    "print(\"Tokenizer saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "229e55c2-ed6a-49df-8bb7-1715011439fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Loaded\n",
      "Random Forest Model Loaded\n",
      "Tokenizer Loaded\n",
      "Vectorizer Loaded\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your text (or 'exit' to quit):  fuck\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Predictions:\n",
      "Logistic Regression: Toxic\n",
      "Random Forest: Toxic\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your text (or 'exit' to quit):  Hello IBM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Predictions:\n",
      "Logistic Regression: Not Toxic\n",
      "Random Forest: Not Toxic\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your text (or 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import Libraries\n",
    "import joblib  # For loading models\n",
    "import numpy as np  # For handling arrays\n",
    "from keras.models import load_model \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# Step 2: Load the Models\n",
    "log_reg_model = joblib.load('logistic_regression_model.pkl')\n",
    "print(\"Logistic Regression Model Loaded\")\n",
    "\n",
    "random_forest_model = joblib.load('random_forest_model.pkl')\n",
    "print(\"Random Forest Model Loaded\")\n",
    "\n",
    "# Load the Tokenizer and Vectorizer\n",
    "tokenizer = joblib.load('tokenizer.pkl')  # Load your tokenizer here\n",
    "print(\"Tokenizer Loaded\")\n",
    "\n",
    "# Load the vectorizer used during model training (this should match what was used)\n",
    "vectorizer = joblib.load('tfidf_vectorizer.pkl')  # Assuming you saved the vectorizer\n",
    "print(\"Vectorizer Loaded\")\n",
    "\n",
    "# Step 4: Define a Function to Make Predictions\n",
    "def predict(text):\n",
    "    # Get features for Logistic Regression and Random Forest\n",
    "    vectorized_features = vectorizer.transform([text]).toarray()  # Get the feature vector\n",
    "    log_reg_prediction = log_reg_model.predict(vectorized_features)\n",
    "    random_forest_prediction = random_forest_model.predict(vectorized_features)\n",
    "\n",
    "    # Combine predictions for final output\n",
    "    final_prediction = log_reg_prediction[0] or random_forest_prediction[0]\n",
    "\n",
    "    return {\n",
    "        \"log_reg\": log_reg_prediction[0],\n",
    "        \"random_forest\": random_forest_prediction[0],\n",
    "        \"final_prediction\": final_prediction\n",
    "    }\n",
    "\n",
    "# Step 5: Input Loop for User Interaction\n",
    "while True:\n",
    "    text_input = input(\"Enter your text (or 'exit' to quit): \")\n",
    "    if text_input.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    predictions = predict(text_input)\n",
    "    \n",
    "    # Step 6: Display Predictions\n",
    "    print(\"\\nModel Predictions:\")\n",
    "    print(f\"Logistic Regression: {'Toxic' if predictions['log_reg'] else 'Not Toxic'}\")\n",
    "    print(f\"Random Forest: {'Toxic' if predictions['random_forest'] else 'Not Toxic'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b20f73dc-be1b-4a44-8c66-56afa7587270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model converted to PMML\n",
      "Random Forest Model converted to PMML\n"
     ]
    }
   ],
   "source": [
    "from sklearn2pmml import PMMLPipeline\n",
    "from sklearn2pmml import sklearn2pmml\n",
    "\n",
    "# Step 9: Convert Logistic Regression and Random Forest models to PMML\n",
    "def convert_sklearn_models_to_pmml():\n",
    "    # Logistic Regression PMML conversion\n",
    "    log_reg_pipeline = PMMLPipeline([(\"classifier\", log_reg_model)])  # Creating a pipeline for Logistic Regression\n",
    "    sklearn2pmml(log_reg_pipeline, \"logistic_regression_model.pmml\", with_repr=True)\n",
    "    print(\"Logistic Regression Model converted to PMML\")\n",
    "\n",
    "    # Random Forest PMML conversion\n",
    "    rf_pipeline = PMMLPipeline([(\"classifier\", random_forest_model)])  # Creating a pipeline for Random Forest\n",
    "    sklearn2pmml(rf_pipeline, \"random_forest_model.pmml\", with_repr=True)\n",
    "    print(\"Random Forest Model converted to PMML\")\n",
    "\n",
    "# Call the functions to convert the models\n",
    "convert_sklearn_models_to_pmml()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
